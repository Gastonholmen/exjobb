\chapter{Data}
\section{Data Collecting}
Having reliable data is a fundamental requirement in building a good model. There are many parameters to consider in optimizing the data collecting process. However,  finding an optimal solution is often impossible as the combinations are endless, but putting some thought into every decision often proves worthwhile. Below, we motivate our choices of sensor placement as well as various parameters.

\subsection{Measurement Setup}


Include graphics of the sensor placement etc. and describe the setup briefly. Possibly mention the $\frac14\lambda$ gap between the sensor and RLM plastic.
\subsection{Measurement Settings}
To ensure that good data is obtained, choosing suitable parameters such as sampling frequency, regions of interest and planning a good measurment setup are all crucial tasks. The sampling frequency is particularly important to consider when working with means that could potentially cause aliasing. One such case is the DFT \citep{lindgren_rootze≈Ωn_sandsten_2013}. If the sampling frequency is too low, we get aliasing etc. etc. 

In order to assure that aliasing is avoided, the maximal frequency component registered by the radar must be surpassed by half the sampling frequency
\begin{equation}
	f_{max} < \frac{f_s}{2}.
\end{equation}
The sampling frequency can be chosen accordingly, assuming the maximal frequency component is known. 

In figure (fig. from previous subsubsection) a vehicle is moving forward with constant speed, having a sensor mounted at the front. As it moves forward, small objects on the ground get closer to the radar sensor with some speed. This gives rise to a doppler frequency being registered by the radar, which is \citep{lien_gillian_karagozler_amihood_schwesig_olson_raja_poupyrev_2016}
\begin{equation}
	f_{d} = \frac{2v_\perp}{\lambda}.
\end{equation}
...


\section{Data exploration}

Good source on PCA
\cite{hyvasrinen_karhunen_oja_2004}
PCA 125-143

Information theory
105-122
Argument for downsampling in range: In an information theoretic framework we interpret a random variable by how unpredicable or unstructured an observation of the variable is. This concept, examining the randomness of a variable, is commonly measured through entropy. Directly related to entropy is mutual information which essentially is how much information each member of a set have on the other members. \cite{hyvasrinen_karhunen_oja_2004}. Ideally one wants measurements that have a low measure of mutual information, meaning that each datapoint contain information not found elsewhere in the set. 

Observing a typical radar sweep (figure \ref{fig:singel_sweep}) we note that points are very closely related on a small range scale, and nearly identical if we were to examine them on a sample by sample basis. One could argue that the mutual information found in the set is very high and that the entropy in each datapoint is low. Hence, to lower the first and increase the latter, one could downsample by some factor $D$ in range without significant loss of information.


PCA 125-143: Through the point and feature selection methods described in previous sections we obtain high dimensional feature vectors. Getting an intuitive feel for such data extracted in these processes is difficult as direct plotting is limited to three dimensions. 

Principal Component Analysis (PCA) is  a classical technique in statistical data analysis which takes a large set of multivariate variables and finds a smaller set of variables with less redundancy. Critically, PCA finds a rotated orthogonal coordinate system such that the elements of the set become uncorrelated. Projecting elements on the principal axes corresponding to the directions of maximal variance a good approximation of the original data in lower dimension is obtained \citep{hyvasrinen_karhunen_oja_2004}.








