\chapter{Data acquisition and preprocessing}

Having reliable data is a fundamental requirement in building a good model. In this chapter we describe the data measurement setup and the data acquisition process used in capturing the dataset used for surface classification. 

\section{Data representation}

A common representation of data acquired by multi-antenna radars is the \emph{datacube} \citep{richards_2014}. The first dimension of the datacube consist of the range measurements. Range measurements are formed from estimating the time-of-flight of a returning wavelet from a target scene. This process forms the shortest time frame possible with sample spacing on the picosecond scale for millimeter-wave radar, and is thus commonly referred to as the \emph{fast time} scale. With sampling frequency $F_s$ new measurements are produced every $1/F_s$ seconds. This sequence of measurements form the second dimension. Due to its much slower rate (on the $1/F_s$ scale) it is referred to as the \emph{slow time} scale. Finally, the last dimension is constructed from the receiver indicies. This intuitively pleasing representation of data acquired by radar arrays are commonly referenced in journal papers when describing for instance beam forming or doppler processing algorithms \citep{gentile_donovan_2018}. 

In this report systems with only a single receiving antenna is used generating data with only fast and slow time dimensions. However, in this project two such systems are uused in parallell, but not synchronized to one another. This means that the sensors take turn measuring their surroundings as opposed to listening to the same returning wavelets. Thus, it would be incorrect to treat these two sensors as the third dimension of datacubes, which would indicate that the two sensors are synchronized.

Instead, we may just as well concatenate the two sensor outputs to form a \emph{data matrix}. If the contents of one radar sensor output with fast time index $d=1...Z$ and slow time index $t=1...Q$ is described with $r(d,t)$, we form a data matrix $\mathbf{R}$ with sensors $r_1(d,t)$ and $r_2(d,t)$ through

\begin{equation}
	\mathbf{R}= 
	\begin{bmatrix}
		r_1(0,0) & r_1(1,0) & \cdots & r_1(Z,0) & r_2(0,0) & \cdots & r_2(Z,0) \\
		r_1(0,1) & r_1(1,1) & \cdots & r_1(Z,1) & r_2(0,1) & \cdots & r_2(Z,1) \\
		\vdots &  \vdots & \ddots & \vdots & \vdots & \ddots &  \vdots \\
		r_1(0,Q) & r_1(0,Q) & \cdots  & r_1(Z,Q) & r_2(0,Q) & \cdots  & r_2(Z,Q) \\
	\end{bmatrix}
	,
\end{equation}
or, more succinctly, as samples $r(n,t) = \mathbf{R}_{t,n}$ with $n=1...2Z$. Each collected data matrix is built up of 50,000 slow time samples, so that $Q=50000$.

\begin{figure}
	\centering
	\includegraphics[scale=0.60]{figs_temp/data_collecting.jpg}
	\caption{Two sensors mounted at the front of a robot collect data while the robot is moving forward. Note that the collected data is split in its \gls{iq} components, whereas the image depicts its absolute values for the sake of clarity.}
	\label{fig:data_collecting}
\end{figure}

\section{Measurement Setup}

As mentioned above, two sensors each capture one data matrix per measurement session. Sensor data is acquired while the robot is moving at a constant pace, illustrated in figure \ref{fig:data_collecting}. Furthermore, two mounting angles are used, where one sensor is facing directly towards the ground while the other has a $22.5^\circ$ tilt forward. The reasoning behind this setup is for each sensor to capture different aspects of the surface below; the sensor placed flat downwards captures a larger component of the specular (mirror-like) scattering process from the ground plane, while the tilted captures more of the non-specular scatterers. 

This idea is illustrated in figure \ref{fig:reflections}. If we are presented with two surfaces of the same material but with different ruggedness, the two will still scatter differently in spite of their equivalent dielectric properties. The scattering processes considered in this work should be highly dependant on the surface structure, where the predictability (or the randomness) should vary from material to material. It is worth noting that the angular spread of the sensor is roughly $30^\circ$ \citep{acconeer_datasheet_a111}, meaning that a $60^\circ$ angle from the sensor is illuminated at once. 


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.9]{figs_temp/reflections.jpg}
	\caption{Using two sensors mounted with different tilts, we can get information about a surface's roughness. For a smooth surface, the flat and tilted sensors yield a very different response, whereas for a rugged surface the responses are more similar.}
	\label{fig:reflections}
\end{figure}

A final consideration is that as the sensors are placed on the inside of the robot plastic chassis, there is a risk for interference between in the region between the plastic and the antenna. To avoid this a small mount was 3D-printed so that the distance to the plastic was $\lambda/4$. Doing this means that any waves propagating back and forth in this region interfere destructively due to the change in polarity and the superposition principle of electromagnetic radiation \citep{griffiths_2018}.

\section{Target Surfaces}
%TODO: Maybe cool figure with the surfaces. 

In this work we wish to see if we can create a binary classifier capable of distinguishing grass from non-grass surfaces. For the application of keeping a robot lawn mower in bounds, it is natural to select other surfaces that commonly borders lawns. With this in mind the surface selection is presented in table \ref{tab:count}, as well as the number of measurement sessions per surface. Each sessions were taken either on different days, or different locations. Note that the total sampling time amounts to $50,000\times42/(F_s\times60)=175$ minutes.

\begin{table}
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		\rowcolor{gray!150}\color{white}\textbf{Surface} & \color{white}\textbf{Num. sessions} \\
		 Grass & 18 \\
		 \rowcolor{gray!25} Asphalt & 6 \\
		 Gravel & 6 \\
		 \rowcolor{gray!25} Soil & 8 \\
		 Tiles & 4 \\ \hline
		 \rowcolor{gray!25} Total & 42 \\
		 \hline
	\end{tabular}
\end{center}
\caption{Measured surface types and number of measurement sessions per surface type.}
\label{tab:count}
\end{table}

\iffalse
\begin{table}
\begin{center}
	\begin{tabular}{|c|c|}
	  	\hline
	  	\cellcolor{gray!150}\color{white}\textbf{Setting} & \cellcolor{gray!150}\color{white}\textbf{Value} \\
	 	 Wavelet duration & 50 ps \\
	  	\cellcolor{gray!25}Sampling frequency & \cellcolor{gray!25}200 Hz \\
	  	Range interval & 7 to 23 cm \\ 
		\hline
  	\end{tabular}	
\end{center}
\caption{Sensor settings.}
\label{tab:sensor_settings}
\end{table}
\fi

\section{Measurement Settings}

The Acconeer \gls{pcr} system has a number of user-defined settings. In this section a few key parameters of these are discussed, namely the range interval sampled, the slow time sampling rate and the wavelet duration. Although finding the appropriate sensor settings requires some level of trial-and-error due to hardware and software limitations, a good starting point can be found using a theoretical perspective. 

\subsection{Sampling rate}
When working with radars and moving targets it is important to select a frequency capable of resolving the maximum speed that the target can have. If a too low frequency is used, aliasing occurs distorting the frequency spectrum \citep{lindgren_rootze≈Ωn_sandsten_2013}. In order to assure that aliasing does not occur, one must select a sampling rate $f_s$ at least twice the received maximal frequency component $f_{max}$. This limit, commonly known as the Nyquist limit \citep{proakis_manolakis_1995}. From section \ref{sec:doppler} we found that the velocity $v$, the carrier wavelength $\lambda_t$ and the \gls{bf} $f_d$ are related through $v \approx \lambda_tf_d/2$. Combining these two, we require from the sampling rate $F_s$ that 

\begin{equation}
\label{eq:nyquist}
		F_{s} \geq 2f_{max} 
		= 2f_d 
		\approx \frac{4v}{\lambda_t}.
\end{equation}

The velocity above is the \emph{radial} velocity. In the measurement setup depicted in figure \ref{fig:sensor_placement}, a vehicle is moving forward with constant speed $v_0$ having a sensor mounted at the front with a 22.5 degree tilt and a 60 degree angular spread. The maximal velocity component that is orthogonal to the sensor occurs at the far end of the radar's view at $22.5^\circ + 30^\circ = 52.5^\circ$ tilt. With $\lambda_t=c/f_t=0.005$ m and the maximum orthogonal velocity component $v_{\perp, max}$ the requirement above becomes

\begin{equation}
	F_s \geq 
	\frac{4v_{\perp, max}}{\lambda_t}
	= \frac{4v_0\sin(52.5^\circ)}{\lambda_t} 
	\approx 190 \text{ Hz}.
\end{equation}

Thus, in order to avoid aliasing, the sampling rate $F_s$ should be at least 190 Hz. 


\begin{figure}[h]
	\centering
	\includegraphics[scale=0.30]{figs_temp/sensor_placement.jpg}
	\caption{Sensor placement in robot chassis. The figure indicates the furthest point visible by the radar.}
	\label{fig:sensor_placement}
\end{figure}
\subsection{Wavelet Duration}

%TODO: Introduce some brief bandwidth concepts here 
The length, or duration, of the transmitted wavelet pulses in a \gls{pcr} system determines the bandwidth. 

The frequency is essentially set for the system used at around 60 GHz without any significant leeway. The duration may however be chosen somewhat freely. Selecting a longer wavelet means transmitting more energy and thus receiving a signal with better SNR. A shorter wavelet has worse SNR, but is capable of resolving finer details of the target. Thus, the wavelet duration parameter becomes a tradeoff between resolution and SNR. One may start with a short wavelet and increase its duration until a reasonable SNR is obtained.  

\subsection{Range Swath}

Finally, the radar measures power over some range interval, also called the \emph{range swath} \citep{richards_2014}. Again, a tradeoff appears. If a short interval is selected we can increase the sampling rate and still stay within the allowed hardware transmission speed limits. However, if the interval becomes too short we may miss useful information we could have collected outside the chosen interval. Thus, a reasonable strategy is to select the most critical range interval and then increase the sampling frequency to its hardware allowed limit. As the distance to the surface plane was roughly 12 cm the furthest distance illuminated is $12/\sin(37.5^\circ)\approx 20$ cm. We should therefore at least have a range swath spanning this region. 

The values chosen for the three parameters are summarized in table \ref{tab:sensor_settings}.

\begin{table}
\begin{center}
	\begin{tabular}{|c|c|}
	  	\hline
	  	\cellcolor{gray!150}\color{white}\textbf{Setting} & \cellcolor{gray!150}\color{white}\textbf{Value} \\
	 	 Wavelet duration & 50 ps \\
	  	\cellcolor{gray!25}Sampling frequency & \cellcolor{gray!25}200 Hz \\
	  	Range interval & 7 to 23 cm \\ 
		\hline
  	\end{tabular}	
\end{center}
\caption{Sensor settings.}
\label{tab:sensor_settings}
\end{table}

\section{Downsampling}
\label{downsampling}

In information theory we interpret and quantify random variables by how unpredictable or unstructured observations of the random variables are \citep{anderson_johnnesson_2006}. Using such a framework, we could argue that variables that contain the same information as others in the same set are obsolete and can be discarded \citep{hyvasrinen_karhunen_oja_2004}, as we ideally we want data that contain information not found elsewhere in the set. 

Using the settings in table \ref{tab:sensor_settings} we obtain 331 range samples per radar measurement in the 7-23 cm range, which means samples are spaced by $(230-70)/331\approx0.48$ mm. Observing a typical radar sweep in figure \ref{fig:single_sweep_iq} we note that points are very closely related on a small range scale, and nearly identical if we were to examine them on a sample by sample basis. Hence individual samples are low on information, and we can downsample by some integer factor $D$, and an offset $F$ without significant loss of information.

Downsampling measurements $r_1(d,t)$ and $r_2(d,t)$ by a factor $D$ with offset $F$ can be expressed as

\begin{equation}
	r_{1,D, F}(d, t) = r_{1}(F+dD,t), 
	\quad \text{and} \quad r_{2,D,F}(d,t) = r_{2}(F+dD,t)
\end{equation}
and the data matrix $r_{D,F}(n,t)$ is formed correspondingly.

\section{Sweep Normalization}

Radar gain can vary significantly from one sensor to the next. This means that faced the same surface, two sensors may exhibit a similar sweep structure but scaled differently. Assuming a models training data has been collected with one sensor, it could therefore be difficult to successfully perform classifications with the same model using a sensor which has a different gain. This is due to the fact that a linear scaling difference between two sensors behaves nonlinearly in the prediction output, due to nonlinearities both in the feature extraction process as well as in the classification process.

A way to overcome this issue is to perform sweep normalization as a preprocessing step. There are multiple ways of performing such a normalization. A simple strategy is to simply divide each sweep with its maximum absolute value. While this may intuitively seem like a good idea, it eliminates signal evolution structures between consecutive captured sweeps - if three consecutive sweeps vary in received signal strength we wish to capture such a behaviour. 

A better solution is to instead have the normalization method depend on several consecutive sweeps. Normalizing using multiple sweeps thus maintain some of their relative amplitude structure. Constructing a set of smaller data matrices with index $m$, consisting of $r_D(n,mT + t)$ for $t=0\text{ }...\text{ }T-1$ for $T$ consecutive sweeps, we can average over the average amplitude in the $m$'th data matrix to form scaled, downsampled data $x(n,m,t)$ through

\begin{equation}
	x(n,m,t) = 
	\frac{r_{D}(n,mT + t)TK}
	{\sum_{n=0}^{K-1}\sum_{\tau=0}^{T-1}|r_{D}(n,mT + \tau)|}.
\end{equation}

While this particular method to form data matrices $x(n,m,\tau)$ may seem odd at this point, we will see in the following chapter that it makes a lot of sense with the feature extraction framework used.
