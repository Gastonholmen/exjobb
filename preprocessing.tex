\chapter{Data Preprocessing}
\section{Downsampling}
Add reference to Information Theoretic part

Since the correlation between neighboring range samples is very high we can downsample without significant loss of information. The downsampling process essentially requires three hyperparameters: A starting range $R_{start}$ and an end range $R_{end}$ where we begin and end our downsampling process respectively, as well as a downsampling factor $D$.

\begin{equation}
	x_D(n, t) = x(R_{start} + nD, t) \quad \text{for}\quad n=0...\frac{R_{end}-R_{start}}{D}
\end{equation}

\section{Sweep Normalization}
The gain of Acconeer radars can vary significantly from one sensor to another. Despite facing towards the very same surface, two sensors may exhibit a similar sweep structure,  yet with very different amplitudes. This could potentially have serious consequences if not handled properly. Assuming measurements for a model's training data have been collected with one sensor, it would be impossible to successfully perform classifications with a sensor which has a very different gain. The recordings would simply have too little resemblence, even though they merely differ by a constant gain factor.

A way to combat this problem is to perform some kind of sweep normalization before proceeding with any other preprocessing. There are numerous ways of doing this. A rather simplistic strategy could be to simply normalize each sweep with its maximum value. While this may intuitively seem like a good idea, it may erroneously normalize sweeps which contain outliers (Is this really a problem? What is it really that makes this method work bad?)

A more robust solution is to compute the average energy of ...

Explain normalization procedure: divide all sweeps within a feature box with the total energy within that feature box. 

Mention this was the best approach, but do not go into detail about the other methods - if so, just mention them briefly.
